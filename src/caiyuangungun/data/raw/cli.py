#!/usr/bin/env python3
"""
Rawæ•°æ®ç®¡ç†CLIå·¥å…·

ç»Ÿä¸€çš„æ•°æ®è·å–ã€æ›´æ–°ã€è¡¥å…¨å·¥å…·ï¼Œæ”¯æŒåˆ†é¡µå’Œå¤šç§è¿è¡Œæ¨¡å¼ã€‚

ä½¿ç”¨ç¤ºä¾‹ï¼š
# 1. æŒ‰é…ç½®è¡¨æ›´æ–°ï¼ˆç°æœ‰çš„updateæ¨¡å¼ï¼‰
python -m caiyuangungun.data.raw.cli update

# 2. å¼ºåˆ¶æ›´æ–°å†å²æ•°æ®ï¼ˆæ— è®ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼‰
python -m caiyuangungun.data.raw.cli force-update --data-types income,balancesheet,cashflow --periods 20240630,20240930

# 3. è¡¥å…¨å†å²æ•°æ®ï¼ˆè‡ªåŠ¨å¯»è·¯è¡¥å…¨ç¼ºå¤±çš„æ•°æ®ï¼‰
python -m caiyuangungun.data.raw.cli backfill --data-types daily,daily_basic --lookback-months 6

# 4. å®šå‘å¼ºåˆ¶æ›´æ–°ï¼ˆæŒ‡å®šæ•°æ®ç±»å‹å’Œåˆ†åŒºï¼‰
python -m caiyuangungun.data.raw.cli targeted-update --data-type income --periods 20240630,20240930
"""

import argparse
import sys
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Set, Optional, Tuple
import pandas as pd

# è·å–é¡¹ç›®æ ¹ç›®å½•
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent.parent.parent
sys.path.insert(0, str(project_root / "src"))

from caiyuangungun.data.raw.archivers.period_archiver import PeriodArchiver
from caiyuangungun.data.raw.archivers.trade_date_archiver import TradeDateArchiver
from caiyuangungun.data.raw.archivers.snapshot_archiver import SnapshotArchiver
from caiyuangungun.data.raw.manifest import DATA_ASSETS
from caiyuangungun.data.raw.ip_check import ensure_shanghai_ip

class RawDataCLI:
    """Rawæ•°æ®ç®¡ç†CLIå·¥å…·"""
    
    # æ”¯æŒçš„æ•°æ®ç±»å‹é…ç½®
    SUPPORTED_DATA_TYPES = {
        # è´¢åŠ¡æŠ¥è¡¨æ•°æ® (PeriodArchiver)
        'income': {
            'archiver': PeriodArchiver,
            'type': 'period',
            'description': 'åˆ©æ¶¦è¡¨'
        },
        'balancesheet': {
            'archiver': PeriodArchiver,
            'type': 'period',
            'description': 'èµ„äº§è´Ÿå€ºè¡¨'
        },
        'cashflow': {
            'archiver': PeriodArchiver,
            'type': 'period',
            'description': 'ç°é‡‘æµé‡è¡¨'
        },
        
        # äº¤æ˜“æ—¥æ•°æ® (TradeDateArchiver)
        'daily': {
            'archiver': TradeDateArchiver,
            'type': 'trade_date',
            'description': 'æ—¥äº¤æ˜“æ•°æ®'
        },
        'daily_basic': {
            'archiver': TradeDateArchiver,
            'type': 'trade_date',
            'description': 'æ—¥åŸºæœ¬ä¿¡æ¯'
        },
        'adj_factor': {
            'archiver': TradeDateArchiver,
            'type': 'trade_date',
            'description': 'å¤æƒå› å­'
        },
        
        # å¿«ç…§æ•°æ® (SnapshotArchiver)
        'stock_basic': {
            'archiver': SnapshotArchiver,
            'type': 'snapshot',
            'description': 'è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯'
        },
        'index_basic': {
            'archiver': SnapshotArchiver,
            'type': 'snapshot',
            'description': 'æŒ‡æ•°åŸºæœ¬ä¿¡æ¯'
        },
        'index_classify': {
            'archiver': SnapshotArchiver,
            'type': 'snapshot',
            'description': 'æŒ‡æ•°åˆ†ç±»'
        },
        'trade_cal': {
            'archiver': SnapshotArchiver,
            'type': 'snapshot',
            'description': 'äº¤æ˜“æ—¥å†'
        }
    }
    
    def __init__(self):
        # é¦–å…ˆè¿›è¡ŒIPåœ°åŒºæ£€æµ‹
        ensure_shanghai_ip()
        
        self.project_root = project_root
        self.data_root = project_root / "data"
        print(f"ğŸš€ Rawæ•°æ®ç®¡ç†CLIå·²åˆå§‹åŒ–")
        print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        print(f"ğŸ’¾ æ•°æ®æ ¹ç›®å½•: {self.data_root}")
    
    def _generate_periods(self, lookback_months: int) -> List[str]:
        """ç”Ÿæˆè´¢åŠ¡æŠ¥è¡¨æœŸé—´åˆ—è¡¨"""
        from dateutil.relativedelta import relativedelta
        
        periods = []
        end_date = datetime.now()
        start_date = end_date - relativedelta(months=lookback_months)
        
        current_date = start_date
        while current_date <= end_date:
            year = current_date.year
            quarter = (current_date.month - 1) // 3 + 1
            month_day = {1: "0331", 2: "0630", 3: "0930", 4: "1231"}[quarter]
            periods.append(f"{year}{month_day}")
            current_date += relativedelta(months=3)
        
        return sorted(list(set(periods)))
    
    def _generate_trade_dates(self, lookback_days: int) -> List[str]:
        """ç”Ÿæˆäº¤æ˜“æ—¥æœŸåˆ—è¡¨"""
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è¯»å–äº¤æ˜“æ—¥å†
        dates = []
        end_date = datetime.now()
        start_date = end_date - timedelta(days=lookback_days)
        
        current_date = start_date
        while current_date <= end_date:
            # è·³è¿‡å‘¨æœ«
            if current_date.weekday() < 5:
                dates.append(current_date.strftime('%Y%m%d'))
            current_date += timedelta(days=1)
        
        return dates
    
    def _get_existing_partitions(self, data_type: str) -> Set[str]:
        """è·å–å·²å­˜åœ¨çš„æ•°æ®åˆ†åŒº"""
        landing_path = self.data_root / "raw" / "landing" / "tushare" / data_type
        if not landing_path.exists():
            return set()
        
        partitions = set()
        for partition_dir in landing_path.iterdir():
            if partition_dir.is_dir():
                partition_name = partition_dir.name.split('=')[1] if '=' in partition_dir.name else partition_dir.name
                partitions.add(partition_name)
        
        return partitions
    
    def _process_with_retry(self, archiver, partition: str, max_retries: int = 3, enable_pagination: bool = True) -> bool:
        """å¸¦é‡è¯•æœºåˆ¶çš„æ•°æ®å¤„ç†"""
        config = self.SUPPORTED_DATA_TYPES[archiver.data_type]
        
        for attempt in range(max_retries):
            try:
                print(f"  ğŸ“¡ å°è¯• {attempt + 1}/{max_retries}: å¤„ç† {partition}...")
                
                if config['type'] == 'period':
                    if enable_pagination and hasattr(archiver, '_process_period_with_pagination'):
                        archiver._process_period_with_pagination(partition)
                    else:
                        archiver._process_period(partition)
                elif config['type'] == 'trade_date':
                    if enable_pagination and hasattr(archiver, '_process_day_with_pagination'):
                        archiver._process_day_with_pagination(partition)
                    else:
                        archiver._process_day(partition)
                elif config['type'] == 'snapshot':
                    archiver.update()
                
                print(f"  âœ… æˆåŠŸå¤„ç† {partition}")
                return True
                
            except Exception as e:
                print(f"  âŒ ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    print(f"  â³ ç­‰å¾… {attempt + 1} ç§’åé‡è¯•...")
                    time.sleep(attempt + 1)
                else:
                    print(f"  ğŸš« è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒå¤„ç† {partition}")
        
        return False
    
    def update_mode(self, data_types: List[str] = None):
        """æŒ‰é…ç½®è¡¨æ›´æ–°æ¨¡å¼ï¼ˆç°æœ‰çš„updateæ¨¡å¼ï¼‰"""
        print(f"\nğŸ”„ æŒ‰é…ç½®è¡¨æ›´æ–°æ¨¡å¼")
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ•°æ®ç±»å‹ï¼Œä½¿ç”¨é…ç½®è¡¨ä¸­çš„æ‰€æœ‰æ”¯æŒç±»å‹
        if not data_types:
            data_types = [asset['name'] for asset in DATA_ASSETS 
                         if asset['name'] in self.SUPPORTED_DATA_TYPES]
        
        print(f"ğŸ“Š å¤„ç†æ•°æ®ç±»å‹: {', '.join(data_types)}")
        
        success_count = 0
        total_count = len(data_types)
        
        for data_type in data_types:
            if data_type not in self.SUPPORTED_DATA_TYPES:
                print(f"âš ï¸  è·³è¿‡ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {data_type}")
                continue
            
            print(f"\n--- å¤„ç† {data_type} ({self.SUPPORTED_DATA_TYPES[data_type]['description']}) ---")
            
            try:
                config = self.SUPPORTED_DATA_TYPES[data_type]
                archiver = config['archiver'](data_type=data_type)
                
                # æ ¹æ®æ•°æ®ç±»å‹ä½¿ç”¨ç›¸åº”çš„æ›´æ–°æ–¹æ³•
                if config['type'] == 'period':
                    archiver.update(lookback_months=24)  # è´¢åŠ¡æ•°æ®å›æº¯24ä¸ªæœˆ
                elif config['type'] == 'trade_date':
                    archiver.update(lookback_days=120)   # äº¤æ˜“æ•°æ®å›æº¯120å¤©
                elif config['type'] == 'snapshot':
                    archiver.update()                    # å¿«ç…§æ•°æ®ç›´æ¥æ›´æ–°
                
                success_count += 1
                print(f"âœ… {data_type} æ›´æ–°å®Œæˆ")
                
            except Exception as e:
                print(f"âŒ {data_type} æ›´æ–°å¤±è´¥: {e}")
        
        print(f"\nğŸ“‹ æ›´æ–°å®Œæˆ: {success_count}/{total_count} ä¸ªæ•°æ®ç±»å‹æˆåŠŸ")
    
    def force_update_mode(self, data_types: List[str], partitions: List[str]):
        """å¼ºåˆ¶æ›´æ–°å†å²æ•°æ®æ¨¡å¼ï¼ˆæ— è®ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼‰"""
        print(f"\nğŸ’ª å¼ºåˆ¶æ›´æ–°å†å²æ•°æ®æ¨¡å¼")
        print(f"ğŸ“Š æ•°æ®ç±»å‹: {', '.join(data_types)}")
        print(f"ğŸ“… åˆ†åŒº: {', '.join(partitions)}")
        
        total_tasks = len(data_types) * len(partitions)
        success_count = 0
        
        for data_type in data_types:
            if data_type not in self.SUPPORTED_DATA_TYPES:
                print(f"âš ï¸  è·³è¿‡ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {data_type}")
                continue
            
            print(f"\n--- å¼ºåˆ¶æ›´æ–° {data_type} ({self.SUPPORTED_DATA_TYPES[data_type]['description']}) ---")
            
            try:
                config = self.SUPPORTED_DATA_TYPES[data_type]
                archiver = config['archiver'](data_type=data_type)
                
                for partition in partitions:
                    if self._process_with_retry(archiver, partition, max_retries=3, enable_pagination=True):
                        success_count += 1
                
            except Exception as e:
                print(f"âŒ åˆ›å»º {data_type} å½’æ¡£å™¨å¤±è´¥: {e}")
        
        print(f"\nğŸ“‹ å¼ºåˆ¶æ›´æ–°å®Œæˆ: {success_count}/{total_tasks} ä¸ªä»»åŠ¡æˆåŠŸ")
    
    def backfill_mode(self, data_types: List[str], lookback_months: int = None, lookback_days: int = None):
        """è¡¥å…¨å†å²æ•°æ®æ¨¡å¼ï¼ˆè‡ªåŠ¨å¯»è·¯è¡¥å…¨ç¼ºå¤±æ•°æ®ï¼‰"""
        print(f"\nğŸ” è¡¥å…¨å†å²æ•°æ®æ¨¡å¼")
        print(f"ğŸ“Š æ•°æ®ç±»å‹: {', '.join(data_types)}")
        
        total_missing = 0
        total_filled = 0
        
        for data_type in data_types:
            if data_type not in self.SUPPORTED_DATA_TYPES:
                print(f"âš ï¸  è·³è¿‡ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {data_type}")
                continue
            
            config = self.SUPPORTED_DATA_TYPES[data_type]
            print(f"\n--- è¡¥å…¨ {data_type} ({config['description']}) ---")
            
            # ç”Ÿæˆåº”è¯¥å­˜åœ¨çš„åˆ†åŒºåˆ—è¡¨
            if config['type'] == 'period':
                months = lookback_months or 24
                expected_partitions = set(self._generate_periods(months))
            elif config['type'] == 'trade_date':
                days = lookback_days or 120
                expected_partitions = set(self._generate_trade_dates(days))
            else:
                print(f"  âš ï¸  å¿«ç…§æ•°æ®ä¸éœ€è¦è¡¥å…¨")
                continue
            
            # è·å–å·²å­˜åœ¨çš„åˆ†åŒº
            existing_partitions = self._get_existing_partitions(data_type)
            
            # æ‰¾å‡ºç¼ºå¤±çš„åˆ†åŒº
            missing_partitions = expected_partitions - existing_partitions
            
            print(f"  ğŸ“Š åº”æœ‰åˆ†åŒº: {len(expected_partitions)}")
            print(f"  ğŸ“Š å·²æœ‰åˆ†åŒº: {len(existing_partitions)}")
            print(f"  ğŸ“Š ç¼ºå¤±åˆ†åŒº: {len(missing_partitions)}")
            
            if not missing_partitions:
                print(f"  âœ… æ— ç¼ºå¤±æ•°æ®")
                continue
            
            total_missing += len(missing_partitions)
            
            # è¡¥å…¨ç¼ºå¤±çš„åˆ†åŒº
            try:
                archiver = config['archiver'](data_type=data_type)
                filled_count = 0
                
                for partition in sorted(missing_partitions):
                    print(f"  ğŸ”§ è¡¥å…¨ç¼ºå¤±åˆ†åŒº: {partition}")
                    if self._process_with_retry(archiver, partition, max_retries=3, enable_pagination=True):
                        filled_count += 1
                
                total_filled += filled_count
                print(f"  ğŸ“ˆ è¡¥å…¨ç»“æœ: {filled_count}/{len(missing_partitions)} ä¸ªåˆ†åŒºæˆåŠŸ")
                
            except Exception as e:
                print(f"  âŒ åˆ›å»º {data_type} å½’æ¡£å™¨å¤±è´¥: {e}")
        
        print(f"\nğŸ“‹ è¡¥å…¨å®Œæˆ: {total_filled}/{total_missing} ä¸ªç¼ºå¤±åˆ†åŒºæˆåŠŸè¡¥å…¨")
    
    def targeted_update_mode(self, data_type: str, partitions: List[str]):
        """å®šå‘å¼ºåˆ¶æ›´æ–°æ¨¡å¼"""
        print(f"\nğŸ¯ å®šå‘å¼ºåˆ¶æ›´æ–°æ¨¡å¼")
        print(f"ğŸ“Š æ•°æ®ç±»å‹: {data_type} ({self.SUPPORTED_DATA_TYPES[data_type]['description']})")
        print(f"ğŸ“… åˆ†åŒº: {', '.join(partitions)}")
        
        if data_type not in self.SUPPORTED_DATA_TYPES:
            print(f"âŒ ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {data_type}")
            return
        
        try:
            config = self.SUPPORTED_DATA_TYPES[data_type]
            archiver = config['archiver'](data_type=data_type)
            
            success_count = 0
            for partition in partitions:
                if self._process_with_retry(archiver, partition, max_retries=3, enable_pagination=True):
                    success_count += 1
            
            print(f"\nğŸ“‹ å®šå‘æ›´æ–°å®Œæˆ: {success_count}/{len(partitions)} ä¸ªåˆ†åŒºæˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºå½’æ¡£å™¨å¤±è´¥: {e}")
    
    def list_supported_types(self):
        """åˆ—å‡ºæ”¯æŒçš„æ•°æ®ç±»å‹"""
        print(f"\nğŸ“‹ æ”¯æŒçš„æ•°æ®ç±»å‹:")
        print(f"{'ç±»å‹':<15} {'å½’æ¡£å™¨':<20} {'æè¿°':<15}")
        print("-" * 50)
        
        for data_type, config in self.SUPPORTED_DATA_TYPES.items():
            archiver_name = config['archiver'].__name__
            description = config['description']
            print(f"{data_type:<15} {archiver_name:<20} {description:<15}")

def main():
    parser = argparse.ArgumentParser(
        description='Rawæ•°æ®ç®¡ç†CLIå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # 1. updateå‘½ä»¤ - æŒ‰é…ç½®è¡¨æ›´æ–°
    update_parser = subparsers.add_parser('update', help='æŒ‰é…ç½®è¡¨æ›´æ–°æ•°æ®')
    update_parser.add_argument('--data-types', type=str, 
                              help='æŒ‡å®šæ•°æ®ç±»å‹ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆä¸æŒ‡å®šåˆ™å¤„ç†æ‰€æœ‰ï¼‰')
    
    # 2. force-updateå‘½ä»¤ - å¼ºåˆ¶æ›´æ–°å†å²æ•°æ®
    force_update_parser = subparsers.add_parser('force-update', help='å¼ºåˆ¶æ›´æ–°å†å²æ•°æ®')
    force_update_parser.add_argument('--data-types', type=str, required=True,
                                    help='æ•°æ®ç±»å‹ï¼Œç”¨é€—å·åˆ†éš”')
    force_update_parser.add_argument('--periods', type=str,
                                    help='æœŸé—´/æ—¥æœŸï¼Œç”¨é€—å·åˆ†éš”')
    force_update_parser.add_argument('--lookback-months', type=int, default=12,
                                    help='å›æº¯æœˆæ•°ï¼ˆç”¨äºè´¢åŠ¡æ•°æ®ï¼‰')
    force_update_parser.add_argument('--lookback-days', type=int, default=60,
                                    help='å›æº¯å¤©æ•°ï¼ˆç”¨äºäº¤æ˜“æ•°æ®ï¼‰')
    
    # 3. backfillå‘½ä»¤ - è¡¥å…¨å†å²æ•°æ®
    backfill_parser = subparsers.add_parser('backfill', help='è¡¥å…¨å†å²æ•°æ®')
    backfill_parser.add_argument('--data-types', type=str, required=True,
                                help='æ•°æ®ç±»å‹ï¼Œç”¨é€—å·åˆ†éš”')
    backfill_parser.add_argument('--lookback-months', type=int, default=24,
                                help='å›æº¯æœˆæ•°ï¼ˆç”¨äºè´¢åŠ¡æ•°æ®ï¼‰')
    backfill_parser.add_argument('--lookback-days', type=int, default=120,
                                help='å›æº¯å¤©æ•°ï¼ˆç”¨äºäº¤æ˜“æ•°æ®ï¼‰')
    
    # 4. targeted-updateå‘½ä»¤ - å®šå‘å¼ºåˆ¶æ›´æ–°
    targeted_parser = subparsers.add_parser('targeted-update', help='å®šå‘å¼ºåˆ¶æ›´æ–°')
    targeted_parser.add_argument('--data-type', type=str, required=True,
                                help='æ•°æ®ç±»å‹')
    targeted_parser.add_argument('--periods', type=str, required=True,
                                help='æœŸé—´/æ—¥æœŸï¼Œç”¨é€—å·åˆ†éš”')
    
    # 5. listå‘½ä»¤ - åˆ—å‡ºæ”¯æŒçš„æ•°æ®ç±»å‹
    subparsers.add_parser('list', help='åˆ—å‡ºæ”¯æŒçš„æ•°æ®ç±»å‹')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        cli = RawDataCLI()
        
        if args.command == 'update':
            data_types = None
            if args.data_types:
                data_types = [dt.strip() for dt in args.data_types.split(',')]
            cli.update_mode(data_types)
            
        elif args.command == 'force-update':
            data_types = [dt.strip() for dt in args.data_types.split(',')]
            
            if args.periods:
                partitions = [p.strip() for p in args.periods.split(',')]
            else:
                # æ ¹æ®æ•°æ®ç±»å‹ç”Ÿæˆé»˜è®¤åˆ†åŒº
                partitions = []
                for data_type in data_types:
                    if data_type in cli.SUPPORTED_DATA_TYPES:
                        config = cli.SUPPORTED_DATA_TYPES[data_type]
                        if config['type'] == 'period':
                            partitions.extend(cli._generate_periods(args.lookback_months))
                        elif config['type'] == 'trade_date':
                            partitions.extend(cli._generate_trade_dates(args.lookback_days))
                partitions = list(set(partitions))  # å»é‡
            
            cli.force_update_mode(data_types, partitions)
            
        elif args.command == 'backfill':
            data_types = [dt.strip() for dt in args.data_types.split(',')]
            cli.backfill_mode(data_types, args.lookback_months, args.lookback_days)
            
        elif args.command == 'targeted-update':
            partitions = [p.strip() for p in args.periods.split(',')]
            cli.targeted_update_mode(args.data_type, partitions)
            
        elif args.command == 'list':
            cli.list_supported_types()
        
        print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
