"""
æµ‹è¯•é€šç”¨æ•°æ®æ¸…æ´—å™¨çš„å„ä¸ªåŠŸèƒ½å’ŒåŸºç¡€æ¸…æ´—æµæ°´çº¿é…ç½®
"""

import pytest
import pandas as pd
import numpy as np
import tempfile
import os
from pathlib import Path
import sys
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°sys.path
project_root = Path(__file__).parent.parent.parent.parent.parent
sys.path.insert(0, str(project_root / "src"))

from caiyuangungun.data.norm.processors.common.universal_data_cleaner import UniversalDataCleaner
from caiyuangungun.data.norm.core.config_manager import ConfigManager


class TestUniversalDataCleaner:
    """æµ‹è¯•é€šç”¨æ•°æ®æ¸…æ´—å™¨"""
    
    def setup_method(self):
        """æµ‹è¯•å‰çš„è®¾ç½®"""
        # åˆ›å»ºæµ‹è¯•ç”¨çš„è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        self.stock_basic_df = pd.DataFrame({
            'symbol': ['000001', '000002', '600000', '600036'],
            'ts_code': ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH'],
            'name': ['å¹³å®‰é“¶è¡Œ', 'ä¸‡ç§‘A', 'æµ¦å‘é“¶è¡Œ', 'æ‹›å•†é“¶è¡Œ']
        })
        
        # åˆ›å»ºBSEæ˜ å°„
        self.bse_mapping = {
            '000001': '000001',
            '000002': '000002', 
            '600000': '600000',
            '600036': '600036'
        }
        
        # åˆå§‹åŒ–æ¸…æ´—å™¨
        self.cleaner = UniversalDataCleaner(
            stock_basic_df=self.stock_basic_df,
            bse_mapping=self.bse_mapping
        )
        
    def test_convert_date_format(self):
        """æµ‹è¯•æ—¥æœŸæ ¼å¼è½¬æ¢åŠŸèƒ½"""
        print("\n=== æµ‹è¯•æ—¥æœŸæ ¼å¼è½¬æ¢åŠŸèƒ½ ===")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'å…¬å‘Šæ—¥æœŸ': ['2025-08-26 00:00:00', '2024-12-31T00:00:00.000Z', '20231201', None],
            'æŠ¥å‘ŠæœŸ': ['2025-06-30T00:00:00.000Z', '2024-09-30 00:00:00', '20231130', ''],
            'NOTICE_DATE': ['2025-08-26 00:00:00', '2024-12-31T00:00:00.000Z', None, '20240101']
        })
        
        print("åŸå§‹æ•°æ®:")
        print(test_data)
        
        # æµ‹è¯•è½¬æ¢å…¬å‘Šæ—¥æœŸ
        result1 = self.cleaner.convert_date_format(
            test_data, 
            field_name='ann_date', 
            source_field='å…¬å‘Šæ—¥æœŸ',
            operation='add'
        )
        print("\nè½¬æ¢å…¬å‘Šæ—¥æœŸå:")
        print(result1[['å…¬å‘Šæ—¥æœŸ', 'ann_date']])
        
        # æµ‹è¯•è½¬æ¢æŠ¥å‘ŠæœŸ
        result2 = self.cleaner.convert_date_format(
            result1,
            field_name='end_date',
            source_field='æŠ¥å‘ŠæœŸ', 
            operation='add'
        )
        print("\nè½¬æ¢æŠ¥å‘ŠæœŸå:")
        print(result2[['æŠ¥å‘ŠæœŸ', 'end_date']])
        
        # æµ‹è¯•è½¬æ¢NOTICE_DATE
        result3 = self.cleaner.convert_date_format(
            result2,
            field_name='notice_date_formatted',
            source_field='NOTICE_DATE',
            operation='add'
        )
        print("\nè½¬æ¢NOTICE_DATEå:")
        print(result3[['NOTICE_DATE', 'notice_date_formatted']])
        
        # éªŒè¯ç»“æœ
        assert 'ann_date' in result3.columns
        assert 'end_date' in result3.columns
        assert 'notice_date_formatted' in result3.columns
        
        # éªŒè¯å…·ä½“è½¬æ¢ç»“æœ
        assert result3.loc[0, 'ann_date'] == '20250826'
        assert result3.loc[1, 'end_date'] == '20240930'
        
    def test_apply_bse_mapping(self):
        """æµ‹è¯•BSEä»£ç æ˜ å°„åŠŸèƒ½"""
        print("\n=== æµ‹è¯•BSEä»£ç æ˜ å°„åŠŸèƒ½ ===")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'è‚¡ç¥¨ä»£ç ': ['000001', '000002', '600000', '999999'],  # æœ€åä¸€ä¸ªä¸åœ¨æ˜ å°„ä¸­
            'SECURITY_CODE': ['000001', '000002', '600000', '888888']
        })
        
        print("åŸå§‹æ•°æ®:")
        print(test_data)
        
        # æµ‹è¯•æ˜ å°„è‚¡ç¥¨ä»£ç 
        result1 = self.cleaner.apply_bse_mapping(
            test_data,
            field_name='è‚¡ç¥¨ä»£ç _mapped',
            source_field='è‚¡ç¥¨ä»£ç ',
            operation='add'
        )
        print("\næ˜ å°„è‚¡ç¥¨ä»£ç å:")
        print(result1[['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨ä»£ç _mapped']])
        
        # æµ‹è¯•æ˜ å°„SECURITY_CODE
        result2 = self.cleaner.apply_bse_mapping(
            result1,
            field_name='SECURITY_CODE_mapped', 
            source_field='SECURITY_CODE',
            operation='add'
        )
        print("\næ˜ å°„SECURITY_CODEå:")
        print(result2[['SECURITY_CODE', 'SECURITY_CODE_mapped']])
        
        # éªŒè¯ç»“æœ
        assert 'è‚¡ç¥¨ä»£ç _mapped' in result2.columns
        assert 'SECURITY_CODE_mapped' in result2.columns
        
        # éªŒè¯æ˜ å°„ç»“æœï¼ˆä¸åœ¨æ˜ å°„ä¸­çš„ä¿æŒåŸå€¼ï¼‰
        assert result2.loc[0, 'è‚¡ç¥¨ä»£ç _mapped'] == '000001'
        assert result2.loc[3, 'è‚¡ç¥¨ä»£ç _mapped'] == '999999'  # ä¸åœ¨æ˜ å°„ä¸­ï¼Œä¿æŒåŸå€¼
        
    def test_add_ts_code(self):
        """æµ‹è¯•æ·»åŠ ts_codeåŠŸèƒ½"""
        print("\n=== æµ‹è¯•æ·»åŠ ts_codeåŠŸèƒ½ ===")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'è‚¡ç¥¨ä»£ç _mapped': ['000001', '000002', '600000', '999999'],  # æœ€åä¸€ä¸ªä¸åœ¨è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ä¸­
            'SECURITY_CODE_mapped': ['000001', '000002', '600000', '888888']
        })
        
        print("åŸå§‹æ•°æ®:")
        print(test_data)
        
        # æµ‹è¯•æ·»åŠ ts_codeï¼ˆåŸºäºè‚¡ç¥¨ä»£ç _mappedï¼‰
        result1 = self.cleaner.add_ts_code(
            test_data,
            field_name='ts_code',
            source_field='è‚¡ç¥¨ä»£ç _mapped',
            operation='add'
        )
        print("\næ·»åŠ ts_codeå:")
        print(result1[['è‚¡ç¥¨ä»£ç _mapped', 'ts_code']])
        
        # æµ‹è¯•æ·»åŠ ts_codeï¼ˆåŸºäºSECURITY_CODE_mappedï¼‰
        result2 = self.cleaner.add_ts_code(
            test_data,
            field_name='ts_code_2',
            source_field='SECURITY_CODE_mapped',
            operation='add'
        )
        print("\nåŸºäºSECURITY_CODE_mappedæ·»åŠ ts_code:")
        print(result2[['SECURITY_CODE_mapped', 'ts_code_2']])
        
        # éªŒè¯ç»“æœ
        assert 'ts_code' in result1.columns
        assert 'ts_code_2' in result2.columns
        
        # éªŒè¯ts_codeç»“æœ
        assert result1.loc[0, 'ts_code'] == '000001.SZ'
        assert result1.loc[2, 'ts_code'] == '600000.SH'
        
    def test_missing_source_field_warnings(self):
        """æµ‹è¯•ç¼ºå¤±æºå­—æ®µæ—¶çš„è­¦å‘Šå¤„ç†"""
        print("\n=== æµ‹è¯•ç¼ºå¤±æºå­—æ®µæ—¶çš„è­¦å‘Šå¤„ç† ===")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆæ•…æ„ç¼ºå°‘æŸäº›å­—æ®µï¼‰
        test_data = pd.DataFrame({
            'existing_field': ['value1', 'value2'],
            'another_field': ['data1', 'data2']
        })
        
        print("åŸå§‹æ•°æ®:")
        print(test_data)
        
        # æµ‹è¯•ç¼ºå¤±æºå­—æ®µçš„æƒ…å†µ
        print("\næµ‹è¯•convert_date_formatç¼ºå¤±æºå­—æ®µ:")
        result1 = self.cleaner.convert_date_format(
            test_data,
            field_name='ann_date',
            source_field='nonexistent_field',  # ä¸å­˜åœ¨çš„å­—æ®µ
            operation='add'
        )
        print("ç»“æœåˆ—:", result1.columns.tolist())
        assert 'ann_date' not in result1.columns  # åº”è¯¥æ²¡æœ‰æ·»åŠ æ–°å­—æ®µ
        
        print("\næµ‹è¯•apply_bse_mappingç¼ºå¤±æºå­—æ®µ:")
        result2 = self.cleaner.apply_bse_mapping(
            test_data,
            field_name='mapped_field',
            source_field='nonexistent_field',  # ä¸å­˜åœ¨çš„å­—æ®µ
            operation='add'
        )
        print("ç»“æœåˆ—:", result2.columns.tolist())
        assert 'mapped_field' not in result2.columns  # åº”è¯¥æ²¡æœ‰æ·»åŠ æ–°å­—æ®µ
        
        print("\næµ‹è¯•add_ts_codeç¼ºå¤±æºå­—æ®µ:")
        result3 = self.cleaner.add_ts_code(
            test_data,
            field_name='ts_code',
            source_field='nonexistent_field',  # ä¸å­˜åœ¨çš„å­—æ®µ
            operation='add'
        )
        print("ç»“æœåˆ—:", result3.columns.tolist())
        assert 'ts_code' not in result3.columns  # åº”è¯¥æ²¡æœ‰æ·»åŠ æ–°å­—æ®µ
        
    def test_empty_mapping_data(self):
        """æµ‹è¯•æ˜ å°„æ•°æ®ä¸ºç©ºæ—¶çš„å¤„ç†"""
        print("\n=== æµ‹è¯•æ˜ å°„æ•°æ®ä¸ºç©ºæ—¶çš„å¤„ç† ===")
        
        # åˆ›å»ºæ²¡æœ‰æ˜ å°„æ•°æ®çš„æ¸…æ´—å™¨
        empty_cleaner = UniversalDataCleaner(
            stock_basic_df=pd.DataFrame(),  # ç©ºçš„è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
            bse_mapping={}  # ç©ºçš„BSEæ˜ å°„
        )
        
        test_data = pd.DataFrame({
            'è‚¡ç¥¨ä»£ç ': ['000001', '600000'],
            'other_field': ['data1', 'data2']
        })
        
        print("åŸå§‹æ•°æ®:")
        print(test_data)
        
        # æµ‹è¯•ç©ºBSEæ˜ å°„
        print("\næµ‹è¯•ç©ºBSEæ˜ å°„:")
        result1 = empty_cleaner.apply_bse_mapping(
            test_data,
            field_name='è‚¡ç¥¨ä»£ç _mapped',
            source_field='è‚¡ç¥¨ä»£ç ',
            operation='add'
        )
        print(result1[['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨ä»£ç _mapped']])
        assert 'è‚¡ç¥¨ä»£ç _mapped' in result1.columns
        assert result1.loc[0, 'è‚¡ç¥¨ä»£ç _mapped'] == '000001'  # åº”è¯¥ä¿æŒåŸå€¼
        
        # æµ‹è¯•ç©ºè‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        print("\næµ‹è¯•ç©ºè‚¡ç¥¨åŸºç¡€ä¿¡æ¯:")
        result2 = empty_cleaner.add_ts_code(
            test_data,
            field_name='ts_code',
            source_field='è‚¡ç¥¨ä»£ç ',
            operation='add'
        )
        print(result2[['è‚¡ç¥¨ä»£ç ', 'ts_code']])
        assert 'ts_code' in result2.columns
        # åº”è¯¥æ ¹æ®ä»£ç å‰ç¼€è‡ªåŠ¨æ·»åŠ åç¼€
        assert result2.loc[0, 'ts_code'] == '000001.SZ'
        assert result2.loc[1, 'ts_code'] == '600000.SH'


def run_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹æµ‹è¯•é€šç”¨æ•°æ®æ¸…æ´—å™¨åŠŸèƒ½...")
    
    test_instance = TestUniversalDataCleaner()
    test_instance.setup_method()
    
    try:
        test_instance.test_convert_date_format()
        print("âœ“ æ—¥æœŸæ ¼å¼è½¬æ¢æµ‹è¯•é€šè¿‡")
        
        test_instance.test_apply_bse_mapping()
        print("âœ“ BSEä»£ç æ˜ å°„æµ‹è¯•é€šè¿‡")
        
        test_instance.test_add_ts_code()
        print("âœ“ æ·»åŠ ts_codeæµ‹è¯•é€šè¿‡")
        
        test_instance.test_missing_source_field_warnings()
        print("âœ“ ç¼ºå¤±æºå­—æ®µè­¦å‘Šæµ‹è¯•é€šè¿‡")
        
        test_instance.test_empty_mapping_data()
        print("âœ“ ç©ºæ˜ å°„æ•°æ®å¤„ç†æµ‹è¯•é€šè¿‡")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def test_basic_cleaning_pipeline():
    """æµ‹è¯•åŸºç¡€æ¸…æ´—æµæ°´çº¿é…ç½®"""
    print("\n" + "="*60)
    print("å¼€å§‹æµ‹è¯•åŸºç¡€æ¸…æ´—æµæ°´çº¿é…ç½®...")
    print("="*60)
    
    try:
        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        config_manager = ConfigManager()
        
        # è·å–åŸºç¡€æ¸…æ´—é…ç½®
        basic_config = config_manager.get_basic_cleaning_config()
        print(f"\nåŸºç¡€æ¸…æ´—é…ç½®åŠ è½½çŠ¶æ€: {'æˆåŠŸ' if basic_config else 'å¤±è´¥'}")
        
        if not basic_config:
            print("âŒ æ— æ³•åŠ è½½åŸºç¡€æ¸…æ´—é…ç½®æ–‡ä»¶")
            return
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'ts_code': ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH'],
            'å…¬å‘Šæ—¥æœŸ': ['2025-08-26 00:00:00', '2024-12-31T00:00:00.000Z', '20231201', '20240101'],
            'æŠ¥å‘ŠæœŸ': ['2025-06-30T00:00:00.000Z', '2024-09-30 00:00:00', '20231130', '20240331'],
            'è¥ä¸šæ”¶å…¥': [1000000, 2000000, 1500000, 1800000],
            'å‡€åˆ©æ¶¦': [100000, 200000, 150000, 180000]
        })
        
        # åˆ›å»ºè‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼ˆåŒ…å«å¿…è¦çš„å­—æ®µï¼‰
        stock_basic_df = pd.DataFrame({
            'symbol': ['000001', '000002', '600000', '600036'],
            'ts_code': ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH'],
            'name': ['å¹³å®‰é“¶è¡Œ', 'ä¸‡ç§‘A', 'æµ¦å‘é“¶è¡Œ', 'æ‹›å•†é“¶è¡Œ'],
            'list_status': ['L', 'L', 'L', 'L'],  # Lè¡¨ç¤ºä¸Šå¸‚
            'list_date': ['19910403', '19910129', '19990810', '20020408'],
            'delist_date': [None, None, None, None]
        })
        
        # åˆ›å»ºBSEæ˜ å°„
        bse_mapping = {
            '000001': '000001',
            '000002': '000002', 
            '600000': '600000',
            '600036': '600036'
        }
        
        # åˆå§‹åŒ–æ¸…æ´—å™¨
        cleaner = UniversalDataCleaner(
            stock_basic_df=stock_basic_df,
            bse_mapping=bse_mapping
        )
        
        print(f"\nåŸå§‹æµ‹è¯•æ•°æ® ({len(test_data)} è¡Œ):")
        print(test_data)
        
        # æµ‹è¯•æ‰€æœ‰æ•°æ®ç±»å‹çš„æ¸…æ´—æµæ°´çº¿
        data_types = ['income_statement', 'balancesheet', 'cashflow', 'fina_indicator', 'daily_data']
        
        for data_type in data_types:
            print(f"\n{'='*50}")
            print(f"æµ‹è¯•æ•°æ®ç±»å‹: {data_type}")
            print(f"{'='*50}")
            
            # è·å–å¯ç”¨çš„æ¸…æ´—æµæ°´çº¿
            enabled_pipelines = config_manager.get_enabled_cleaning_pipelines(data_type)
            
            if not enabled_pipelines:
                print(f"âš ï¸  æ•°æ®ç±»å‹ {data_type} æ²¡æœ‰å¯ç”¨çš„æ¸…æ´—æµæ°´çº¿")
                continue
            
            print(f"å¯ç”¨çš„æ•°æ®æºæ•°é‡: {len(enabled_pipelines)}")
            
            for source_name, pipeline_steps in enabled_pipelines.items():
                print(f"\n--- å¤„ç†æ•°æ®æº: {source_name} ---")
                print(f"æ¸…æ´—æ­¥éª¤æ•°é‡: {len(pipeline_steps)}")
                
                # å¤åˆ¶æµ‹è¯•æ•°æ®ç”¨äºæ¸…æ´—
                current_data = test_data.copy()
                
                # æ‰§è¡Œæ¸…æ´—æµæ°´çº¿
                for i, step in enumerate(pipeline_steps, 1):
                    function_name = step.get('function')
                    params = step.get('params', {})
                    
                    print(f"  æ­¥éª¤ {i}: {function_name}")
                    print(f"    å‚æ•°: {params}")
                    
                    try:
                        # æ‰§è¡Œæ¸…æ´—å‡½æ•°
                        if hasattr(cleaner, function_name):
                            func = getattr(cleaner, function_name)
                            current_data = func(current_data, **params)
                            print(f"    âœ“ æ‰§è¡ŒæˆåŠŸï¼Œå½“å‰æ•°æ®å½¢çŠ¶: {current_data.shape}")
                        else:
                            print(f"    âŒ æ¸…æ´—å‡½æ•° {function_name} ä¸å­˜åœ¨")
                    
                    except Exception as e:
                        print(f"    âŒ æ‰§è¡Œå¤±è´¥: {e}")
                
                print(f"\n{source_name} æ¸…æ´—åçš„æ•°æ®:")
                print(current_data)
                print(f"æ¸…æ´—ååˆ—å: {list(current_data.columns)}")
                
                # æ£€æŸ¥æ˜¯å¦æ·»åŠ äº†é¢„æœŸçš„åˆ—
                expected_columns = ['ts_code']  # æ‰€æœ‰æµæ°´çº¿éƒ½åº”è¯¥æ·»åŠ ts_code
                for col in expected_columns:
                    if col in current_data.columns:
                        print(f"  âœ“ æˆåŠŸæ·»åŠ åˆ—: {col}")
                    else:
                        print(f"  âš ï¸  æœªæ‰¾åˆ°é¢„æœŸåˆ—: {col}")
        
        print(f"\n{'='*60}")
        print("ğŸ‰ åŸºç¡€æ¸…æ´—æµæ°´çº¿æµ‹è¯•å®Œæˆï¼")
        print(f"{'='*60}")
        
    except Exception as e:
        print(f"\nâŒ åŸºç¡€æ¸…æ´—æµæ°´çº¿æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è¿è¡ŒåŸºç¡€åŠŸèƒ½æµ‹è¯•
    run_tests()
    
    # è¿è¡ŒåŸºç¡€æ¸…æ´—æµæ°´çº¿é…ç½®æµ‹è¯•
    test_basic_cleaning_pipeline()