#!/usr/bin/env python3
"""
æ£€æŸ¥åˆ†é¡µæµ‹è¯•ç»“æœä¸­çš„é‡å æƒ…å†µ

ç”¨äºéªŒè¯åˆ†é¡µé€»è¾‘æ˜¯å¦æ­£ç¡®ï¼Œç‰¹åˆ«æ˜¯æ£€æŸ¥ç›¸é‚»é¡µé¢ä¹‹é—´æ˜¯å¦æœ‰é¢„æœŸçš„100è¡Œé‡å 
"""

import pandas as pd
from pathlib import Path

def analyze_pagination_overlap(parquet_file):
    """åˆ†æåˆ†é¡µé‡å æƒ…å†µ"""
    
    if not Path(parquet_file).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {parquet_file}")
        return
    
    print("ğŸ” åˆ†æåˆ†é¡µé‡å æƒ…å†µ")
    print("=" * 50)
    
    # è¯»å–æ•°æ®
    df = pd.read_parquet(parquet_file)
    
    print(f"ğŸ“Š åŸºæœ¬ä¿¡æ¯:")
    print(f"   æ€»è®°å½•æ•°: {len(df):,}")
    print(f"   æ€»é¡µæ•°: {df['_page'].nunique()}")
    print(f"   æ—¥æœŸèŒƒå›´: {df['ann_date'].min()} - {df['ann_date'].max()}")
    
    # æŒ‰é¡µåˆ†ç»„åˆ†æ
    pages = sorted(df['_page'].unique())
    print(f"\nğŸ“„ æŒ‰é¡µåˆ†æ:")
    
    for page in pages:
        page_data = df[df['_page'] == page]
        offset = page_data['_offset'].iloc[0]
        print(f"   ç¬¬{page}é¡µ: {len(page_data):,}æ¡è®°å½•, offset={offset}")
    
    # é‡å åˆ†æ
    print(f"\nğŸ”„ é‡å åˆ†æ:")
    
    for i in range(len(pages) - 1):
        current_page = pages[i]
        next_page = pages[i + 1]
        
        current_data = df[df['_page'] == current_page]
        next_data = df[df['_page'] == next_page]
        
        # åˆ›å»ºå”¯ä¸€é”®è¿›è¡Œå¯¹æ¯”
        current_keys = set(current_data['ts_code'] + '_' + current_data['ann_date'].astype(str) + '_' + current_data['end_date'].astype(str))
        next_keys = set(next_data['ts_code'] + '_' + next_data['ann_date'].astype(str) + '_' + next_data['end_date'].astype(str))
        
        overlap = current_keys.intersection(next_keys)
        overlap_count = len(overlap)
        
        print(f"   ç¬¬{current_page}é¡µ ä¸ ç¬¬{next_page}é¡µ:")
        print(f"     é‡å è®°å½•æ•°: {overlap_count}")
        
        if overlap_count == 100:
            print(f"     âœ… é‡å æ•°é‡æ­£ç¡®ï¼")
        elif overlap_count > 0:
            print(f"     âš ï¸  é‡å æ•°é‡å¼‚å¸¸ï¼ˆæœŸæœ›100è¡Œï¼‰")
        else:
            print(f"     âŒ æ— é‡å ï¼Œå¯èƒ½æœ‰æ•°æ®ä¸¢å¤±")
    
    # æ•´ä½“å»é‡åˆ†æ
    print(f"\nğŸ“ˆ æ•´ä½“æ•°æ®è´¨é‡:")
    unique_df = df.drop_duplicates(subset=['ts_code', 'ann_date', 'end_date'])
    duplicate_count = len(df) - len(unique_df)
    
    print(f"   åŸå§‹è®°å½•æ•°: {len(df):,}")
    print(f"   å»é‡åè®°å½•æ•°: {len(unique_df):,}")
    print(f"   é‡å¤è®°å½•æ•°: {duplicate_count:,}")
    
    # æœŸæœ›é‡å æ•°
    expected_overlap = (len(pages) - 1) * 100
    print(f"   æœŸæœ›é‡å æ•°: {expected_overlap}")
    
    if duplicate_count == expected_overlap:
        print(f"   âœ… é‡å æ•°é‡å®Œå…¨ç¬¦åˆé¢„æœŸï¼")
    else:
        print(f"   âš ï¸  é‡å æ•°é‡ä¸é¢„æœŸä¸ç¬¦")
    
    # ä¿å­˜å»é‡æ•°æ®
    if duplicate_count > 0:
        output_file = Path(parquet_file).parent / f"{Path(parquet_file).stem}_deduplicated.parquet"
        unique_df.to_parquet(output_file, index=False)
        print(f"\nğŸ’¾ å»é‡æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    
    return {
        'total_records': len(df),
        'unique_records': len(unique_df),
        'duplicate_records': duplicate_count,
        'pages': len(pages),
        'expected_overlap': expected_overlap,
        'overlap_correct': duplicate_count == expected_overlap
    }

if __name__ == "__main__":
    # æ£€æŸ¥æµ‹è¯•ç»“æœæ–‡ä»¶
    test_files = [
        "pagination_test_result.parquet",
        "pagination_test_result_unique.parquet"
    ]
    
    for file_name in test_files:
        if Path(file_name).exists():
            print(f"\n{'='*60}")
            print(f"åˆ†ææ–‡ä»¶: {file_name}")
            print(f"{'='*60}")
            analyze_pagination_overlap(file_name)
        else:
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_name}")
